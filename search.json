[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMP/STAT212 Portfolio",
    "section": "",
    "text": "Welcome\nWelcome to my online portfolio for COMP/STAT112 course taken at Macalester College. Please, use the side bar on the left for navigation.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "src/pv/pv-01.html",
    "href": "src/pv/pv-01.html",
    "title": "Professional Viz Sample",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Prof Viz",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Professional Viz Sample</span>"
    ]
  },
  {
    "objectID": "src/tt/hw01-tt.html",
    "href": "src/tt/hw01-tt.html",
    "title": "Homework 01 – TidyTuesday 09/02/2025",
    "section": "",
    "text": "TidyTuesday Section\nExplore the week’s TidyTuesday challenge. Develop a research question, then answer it through a short data story with effective visualization(s). Provide sufficient background for readers to grasp your narrative.\nCode#Necessary Libraries\n#| include: false\n#| echo: false\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(hrbrthemes)\nlibrary(viridis)",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Homework 01 -- TidyTuesday 09/02/2025</span>"
    ]
  },
  {
    "objectID": "src/tt/hw01-tt.html#importing-data",
    "href": "src/tt/hw01-tt.html#importing-data",
    "title": "Homework 01 – TidyTuesday 09/02/2025",
    "section": "Importing Data",
    "text": "Importing Data\nReading in the data both about the families and genus of the frogs as well as individual frog ID events. The individual observation events were recorded frog calls by citizen scientists in Australia. The frogs were then identified via their calls by experts.\n\nCodeFrog_ID &lt;- read.csv(\"tidytuesday/data/2025/2025-09-02/frogID_data.csv\")\nFrog_names &lt;- read.csv(\"tidytuesday/data/2025/2025-09-02/frog_names.csv\")\n\n\nResearch Question: What subfamilies are the most abundant in Australia, and when are they the most abundant?",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Homework 01 -- TidyTuesday 09/02/2025</span>"
    ]
  },
  {
    "objectID": "src/tt/hw01-tt.html#exploring-the-data",
    "href": "src/tt/hw01-tt.html#exploring-the-data",
    "title": "Homework 01 – TidyTuesday 09/02/2025",
    "section": "Exploring the Data",
    "text": "Exploring the Data\nIn order to create visualizations and have subfamilies corresponding to each observation I had to join the two different data sets by their scientific name.\n\nCode#Joining data sets together via scientific name and getting month of the observations\nFrog_expanded &lt;- \n  left_join(Frog_ID, Frog_names, by = \"scientificName\") |&gt; \n  mutate(eventDate = as.Date(eventDate)) |&gt; \n  mutate(month = format(eventDate, \"%b\")) \n\n\nI then created a table that shows the counts of each subfamily of frog for each month over the year of 2023 in order to get an idea of what family was most abundant and when.\n\nCode#Demonstrating the count of each subfamily for each month\nFrog_expanded |&gt; \n  na.omit(subfamily) |&gt; #omiting observations that do not have a subfamily, excludes &gt;9000 observations\n  count(month, subfamily) |&gt; \n  mutate(month = factor(month, levels = month.abb, ordered = TRUE)) |&gt; \n  arrange(month)\n\n   month     subfamily     n\n1    Jan         Hylid  8664\n2    Jan  Microhylidae   155\n3    Jan  Myobatrachid  7021\n4    Jan         Ranid    12\n5    Jan          Toad   282\n6    Feb         Hylid  3675\n7    Feb  Microhylidae   103\n8    Feb  Myobatrachid  4735\n9    Feb         Ranid     5\n10   Feb          Toad   201\n11   Mar         Hylid  1516\n12   Mar  Microhylidae    53\n13   Mar  Myobatrachid  4697\n14   Mar         Ranid    15\n15   Mar          Toad   112\n16   Apr         Hylid   883\n17   Apr  Microhylidae    21\n18   Apr  Myobatrachid  5810\n19   Apr         Ranid    22\n20   Apr          Toad    36\n21   May         Hylid   630\n22   May  Microhylidae     7\n23   May  Myobatrachid  3270\n24   May         Ranid    13\n25   May          Toad     9\n26   Jun         Hylid  1291\n27   Jun  Microhylidae    30\n28   Jun  Myobatrachid  5002\n29   Jun         Ranid    13\n30   Jun          Toad    12\n31   Jul         Hylid  1476\n32   Jul  Microhylidae    60\n33   Jul  Myobatrachid  7471\n34   Jul         Ranid    21\n35   Jul          Toad    36\n36   Aug         Hylid  2634\n37   Aug  Microhylidae    24\n38   Aug  Myobatrachid 12016\n39   Aug         Ranid    18\n40   Aug          Toad    18\n41   Sep         Hylid  5992\n42   Sep  Microhylidae    48\n43   Sep  Myobatrachid 12323\n44   Sep         Ranid    12\n45   Sep          Toad    74\n46   Oct         Hylid  6851\n47   Oct  Microhylidae    28\n48   Oct  Myobatrachid  8677\n49   Oct         Ranid    11\n50   Oct          Toad    59\n51   Nov         Hylid 11195\n52   Nov  Microhylidae    38\n53   Nov  Myobatrachid  9862\n54   Nov         Ranid    19\n55   Nov          Toad   209\n\n\nIt is important to note that in this case there are no observations for the month of December, so we cannot make a blanket statement saying the months Nov-Jan for example, as strickly speaking it is not true.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Homework 01 -- TidyTuesday 09/02/2025</span>"
    ]
  },
  {
    "objectID": "src/tt/hw01-tt.html#visualizations",
    "href": "src/tt/hw01-tt.html#visualizations",
    "title": "Homework 01 – TidyTuesday 09/02/2025",
    "section": "Visualizations",
    "text": "Visualizations\nIn order to get a better idea of the abundance of each family in comparison to the overall density for each month I created the following visualization.\n\nCode#Shows the overall amount of frogs over the year compared to the \nFrog_expanded |&gt; \n  na.omit(subfamily) |&gt;\n  ggplot(aes(x = eventDate)) + \n  geom_density(aes(fill = subfamily), alpha = 0.5) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 29, alpha = 0.5) + \n  theme_minimal() + \n  scale_fill_viridis_d() + \n  labs(x = \"Date\", y = \"Density\", title = \"Density of Frogs and their Subfamilies over Time\", subtitle = \"2023\", fill = \"Subfamily\")\n\n\n\n\n\n\n\nAs we can see in above visualization is that frog calls tend to be more abundant October to January which is spring to summer in Australia. Toads most abundant around January-Febuary, late season. In comparison, Hylids are most abundant in December and January, mid to late season. Myobatrachid peaked in October as well as November. Ranid stay pretty consistent throughout the year. However the visuals layering of all the different subfamilies make it difficult to pull out exact measurements. For example, no trends for Microhylidae can be distinguished. The follow visualization splits all the different subfamiles so that they can be better compared against one another rather than the general trend.\n\nCode#Shows the distribution of each subfamily over the course of a year\nFrog_expanded |&gt; \n  na.omit(subfamily) |&gt;\n  ggplot(aes(x = eventDate, fill = subfamily)) +\n  geom_density() +\n  facet_wrap(~subfamily) + \n  labs(title = \"Distribution of Subfamilies\", subtitle = \"2023\", x = \"Date\", y = \"Probability Density\", fill = \"Subfamily\") + \n  theme_minimal() + \n  scale_fill_viridis_d()\n\n\n\n\n\n\n\nFrom this we can tell much more distinctly that Frogs that fall under the Microhylidae family tend to peak in January-Feburary while staying relatively consistent the rest of the year. However while this visual allows you to compare the density of each species relative to the total of each species not the total number of frogs or count. The following visualization addresses this issue.\n\nCode# Function to hide every other label\nevery_other_label &lt;- function(x) {\n      labels &lt;- as.character(x)\n      labels[seq(2, length(labels), 2)] &lt;- \"\"\n      return(labels)}\n\n#Shows the proportion of the different frog families over the course of the year \nFrog_expanded |&gt;\n  na.omit(subfamily) |&gt;\n  mutate(month = factor(month, levels = month.abb, ordered = TRUE)) |&gt; \n  ggplot(aes(x = month, , fill = subfamily)) + \n  geom_bar() + \n  facet_wrap(~subfamily) + \n  scale_fill_viridis_d() + \n  scale_x_discrete(labels = every_other_label) + \n  labs(x = \"Month\", y = \"Number of Frogs\", title = \"The Number of Frogs of each Subfamily per Month\", subtitle = \"2023\", fill = \"Subfamily\")\n\n\n\n\n\n\n\nThrough this visual we can clearly see that the Myobatrachid of frogs are the most abundant year round and make up most of the frogs that were documented in Australia in 2023. Hylids are the second most common subfamily, followed by Toad and Microhylidae and lastly Ranid. However because the last 3 categories are all significantly smaller than Hylids and Myobatrachid it is difficult to compare them.\nNevertheless we have answered the research question that Myobatrachids are the most abundant Frog subfamily in Australia and are more relatively abundant during the months of August to November.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Homework 01 -- TidyTuesday 09/02/2025</span>"
    ]
  },
  {
    "objectID": "src/tt/hw02-tt.html",
    "href": "src/tt/hw02-tt.html",
    "title": "Homework 02",
    "section": "",
    "text": "TidyTuesday Section (optional)\nExplore the week’s TidyTuesday challenge. Develop a research question, then answer it through a short data story with effective visualization(s). Provide sufficient background for readers to grasp your narrative.\nCode#Necessary Libraries\n#| include: false\n#| echo: false\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(hrbrthemes)\nlibrary(viridis)\nlibrary(tidytuesdayR)",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "src/tt/hw02-tt.html#tidytuesday-section-optional",
    "href": "src/tt/hw02-tt.html#tidytuesday-section-optional",
    "title": "Homework 02",
    "section": "",
    "text": "Instructions\n\n\n\nYou can count work on this week’s TidyTuesday toward the exceptional work required for an A in the Homework component.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "src/tt/hw02-tt.html#importing-data",
    "href": "src/tt/hw02-tt.html#importing-data",
    "title": "Homework 02",
    "section": "Importing Data",
    "text": "Importing Data\nReading in the data about individual countries as well as their rank by year. In this case they were scored based on the number of destinations that passport could travel to with no visa requried. This plays into the rank of the passport which is essentially its travel power.\n\nCodett_data &lt;- tt_load(\"2025-09-09\")\ncountry &lt;- tt_data$country_lists\nyear &lt;- tt_data$rank_by_year\n\n\nResearch Question: How has the power of different regions passports shifted over time? What is the most powerful passport?",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "src/tt/hw02-tt.html#exploring-the-data",
    "href": "src/tt/hw02-tt.html#exploring-the-data",
    "title": "Homework 02",
    "section": "Exploring the Data",
    "text": "Exploring the Data\n\nCode#Joining the \ncountry_expanded &lt;- \n  full_join(country, year)\n\n\n\nCodecountry_expanded |&gt; \n  mutate(visa_free_count = as.numeric(visa_free_count)) |&gt; \n  group_by(region) |&gt; \n  summarise(Mean_Visa = mean(visa_free_count), Mean_rank = mean(rank))\n\n# A tibble: 7 × 3\n  region      Mean_Visa Mean_rank\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;\n1 AFRICA           49.7      77.5\n2 AMERICAS        109.       36.0\n3 ASIA             68.4      65.6\n4 CARIBBEAN        95.7      45.8\n5 EUROPE          131.       22.4\n6 MIDDLE EAST      57.0      74.0\n7 OCEANIA          92.6      45.2\n\n\nIn this table we can see that that Europe has the best overall mean rank for its countries and that passports from Europe tend to be let into a lot more countries. This is then followed by passports from the Americas, then the Caribbean. In last place is Africa.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "src/tt/hw02-tt.html#visualizations",
    "href": "src/tt/hw02-tt.html#visualizations",
    "title": "Homework 02",
    "section": "Visualizations",
    "text": "Visualizations\nIn order to get a better idea on how these trends have changed overtime I created the following visualizations.\n\nCoderegion &lt;- country_expanded |&gt; \n  mutate(visa_free_count = as.numeric(visa_free_count)) |&gt; \n  group_by(region, year) |&gt; \n  summarise(Mean_Visa = mean(visa_free_count), Mean_rank = mean(rank))\n\nregion |&gt; \n  ggplot() + \n  geom_line(aes(x = year, y = Mean_Visa, color = region), stat = \"smooth\", size = 2) + \n  theme_classic(base_size = 13) +  \n  scale_y_continuous(limits = c(0,200), breaks = seq(0, 200, by = 50)) + \n  scale_x_continuous(limits = c(2006,2025), expand = c(0,0)) + \n  theme(\n      panel.grid.minor = element_blank(),\n      axis.ticks.x = element_blank(),\n      plot.title = element_text(face = \"bold\", size = 15),\n      plot.title.position = \"plot\", \n  ) + \n   scale_color_viridis_d() + \n  labs(title = \"Average number of visa free entries over time\", subtitle = \"per region of the world\", x = \"Year\", y = \"Mean Visa Free Count\", color = \"Region\", caption = \"Made by: Tori Duckworth, Date: Sep.15,2025, Source: TidyTuesday 09-09-25\") + \n  geom_vline(aes(xintercept = 2013), linetype = \"dotted\", color = \"gray50\") + \n  geom_text(aes(x = 2014, y = 200, label = \"2013\"), color = \"gray50\", size = 4) + \n  labs(alt = \"alt.text = line graph showing the average number of countries a passport can enter without a visa per region over time. We can clearly see that Europe has the most passports that can visit the most counties without visas, followed by the Americas, and despite rising overtime they have not changed position. Following behind them is the caribbean followed by oceania, which are now about the same level in recent years. Then passports from Asia, the Middle east and Africa follow. There is a line marking 2013 as that is when there seems to be a global shift in the trend of allowing more visa free travel, going from a steady about 45 degree angle incline to plataueing for a year, followed by a much slower climb\")\n\n\n\n\n\n\n\nIn this visualization we can clearly see that the mean number of countries each region’s passports allow people into without visas has increase overtime. In fact they were all following a similar slope until 2013 where there was a significant bump and then most regions plateaued before steadily rising a lot slower. It is unclear what global event could have caused this stalling in the rise of freedom to travel, but the pace has not quite recovered.\n\nCodeBest_passport &lt;- country_expanded |&gt; \n  filter(region == \"EUROPE\") |&gt; \n  mutate(rank = as.numeric(rank)) |&gt; \n  group_by(country) |&gt; \n  filter(any(rank == 1)) |&gt; \n  ungroup()\n  \nBest_passport |&gt;   \n  ggplot() +\n  geom_line(aes(x = year, y = rank, color = country), stat = \"smooth\", size = 2) + \n  theme_classic(base_size = 13) +  \n  scale_y_continuous(limits = c(0,7), breaks = seq(0, 7, by = 2)) + \n  scale_x_continuous(limits = c(2006,2025), expand = c(0,0)) + \n  theme(\n      panel.grid.minor = element_blank(),\n      axis.ticks.x = element_blank(),\n      plot.title = element_text(face = \"bold\", size = 15),\n      plot.title.position = \"plot\", \n  ) + \n   scale_color_viridis_d() + \n  labs(title = \"Best Passport Overtime\", subtitle = \"from Europe\", x = \"Year\", y = \"Rank\", color = \"Country\", caption = \"Made by: Tori Duckworth, Date: Sep.15,2025, Source: TidyTuesday 09-09-25\") + \n  scale_y_reverse() + \n  labs(alt = \"This graph shows 8 European countries who have all been ranked number one at some point from 2006-2025.  Denmark was ranked the best for about 8 years, until around 2013 when both Sweden and the UK were around first. Then Germany became the top rated passport and remained that way until 2025 when Spain over took it. There is a lot of fluctiation between countries and over time.\")\n\n\n\n\n\n\n\nBy looking at this graph, it seems that Denmark was ranked the best for about 8 years, until around 2013 when both Sweden and the UK were around first. Then Germany became the top rated passport and remained that way until 2025 when Spain over took it. However, while this graph shows the changes it doesn’t give us a definitive answer, which I do in the following short table.\n\nCodeBest_passport |&gt; \n  group_by(country) |&gt; \n  summarise(Mean_rank = mean(rank)) |&gt; \n  arrange(Mean_rank) \n\n# A tibble: 8 × 2\n  country        Mean_rank\n  &lt;chr&gt;              &lt;dbl&gt;\n1 Germany             2.2 \n2 Finland             2.4 \n3 Denmark             2.65\n4 Sweden              2.9 \n5 Italy               3.3 \n6 Spain               3.65\n7 France              3.95\n8 United Kingdom      4.15\n\n\nThrough this we can in fact see that Germany has been most consistently the top rated passport. However Finland and Denmark are not far behind. Despite one time taking the first place spot, the UK is last of the 8 European countries in terms of consistent rank.\nAll in all these visualizations tell us that the rate of the number of countries each passport can get a holder in somewhere has slowed down compared to the early 2000s, although still is increasing. Individiuals from Europes passports on average get them into many more countries without a visa, around 131 to be exact, while if your are a German passport holder you have the ultimate travel power.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "src/ica/Review.html",
    "href": "src/ica/Review.html",
    "title": "Cleaning SFO Weather Data",
    "section": "",
    "text": "Exercise\nCarryout the following steps to clean and save the San Francisco Weather data. Make sure to download and add the data file to your portfolio repository as instructed.\nCodelibrary(tidyverse)\nlibrary(readr) #To get read_csv in the CSV\n\n#Step 1\nweather_data &lt;- read_csv(\"../../data/raw/weather.csv\") #Reading in the Data\nCode#Step 2\n#Cleaning out large value in PrecipYr\nweather_clean &lt;- weather_data |&gt; \n  mutate(PrecipYr &lt;- na_if(PrecipYr, 99999))\nCode#Step 3\n#Creating variable that shows the day of the year\nweather_clean &lt;- weather_data |&gt; \n  arrange(Month, Day) |&gt; \n  mutate(dateInYear &lt;- seq(from = 1, to = 365, by = 1))\nCode#Step 4\n#Creating variable that shows 3 letter month abbreviation\nweather_clean &lt;- weather_data |&gt; \n  mutate(month_name &lt;- month.abb[Month])\nCode#Step 5\n#Saving the data to another source \nwrite_csv(weather_clean, file = \"../../data/processed/weather_clean.csv\")",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cleaning SFO Weather Data</span>"
    ]
  },
  {
    "objectID": "src/ica/Review.html#exercise",
    "href": "src/ica/Review.html#exercise",
    "title": "Cleaning SFO Weather Data",
    "section": "",
    "text": "Read in the weather data in this file with the correct relative file path after you move it to the instructed location.\n\n\n\nThere is a variable that has values that don’t make sense in the data context. Figure out which variable this is and clean it up by making those values missing using na_if().\n\n\n\nCreate a variable called dateInYear that indicates the day of the year (1-365) for each case. (Jan 1 should be 1, and Dec 31 should be 365).\n\n\n\nCreate a variable called month_name that shows the 3-letter abbreviation for each case.\n\n\n\nSave the wrangled data to the data/processed/ folder using write_csv(). Name this file weather_clean.csv. Look up the documentation for this function by typing ?write_csv in the Console. You’ll need to write an appropriate relative path.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cleaning SFO Weather Data</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html",
    "href": "src/ica/Advanced_data_viz.html",
    "title": "3 Advanced Data Viz",
    "section": "",
    "text": "🧩 Learning Goals\nBy the end of this lesson, you should be able to:",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#learning-goals",
    "href": "src/ica/Advanced_data_viz.html#learning-goals",
    "title": "3 Advanced Data Viz",
    "section": "",
    "text": "Navigate ggplot2 reference page to find needed functions for a desired visualization\nNavigate the different sections of a function help page to construct desired plot features, in particular,\n\nNavigate the Usage section to identify arguments that must be set\nNavigate the Arguments section to understand how arguments work\nNavigate the Aesthetics section to learn how plot appearance can be controlled\nNavigate the Examples section for some usage examples\n\n\nIdentify when to use different data arguments within ggplot() and geom_() layers",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#introduction",
    "href": "src/ica/Advanced_data_viz.html#introduction",
    "title": "3 Advanced Data Viz",
    "section": "Introduction 1\n",
    "text": "Introduction 1\n\nIn this lesson, we are going to recreate NYTimes 2015 Temperature Visualization (html) using data from San Francisco (SFO) in 2011.\n\n\nScreenshot of NYTimes 2015 Temperature Visualization",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#reading-data",
    "href": "src/ica/Advanced_data_viz.html#reading-data",
    "title": "3 Advanced Data Viz",
    "section": "Reading Data",
    "text": "Reading Data\nRun the code chunk below to load the tidyverse package and read in the San Francisco weather data.\n\nCodelibrary(tidyverse)\nweather &lt;- read_csv(\"https://mac-stat.github.io/data/sfo_weather.csv\")",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#understanding-data",
    "href": "src/ica/Advanced_data_viz.html#understanding-data",
    "title": "3 Advanced Data Viz",
    "section": "Understanding Data",
    "text": "Understanding Data\nBelow is the codebook of the data. Familiarize yourself with the meaning of each variable. Use the codebook as a reference when using the data.\n\n\nMonth: Month of the year (1-12)\n\nDay: Day within the month (1-31)\n\nLow/High: Low/high temperature this day\n\nNormalLow/NormalHigh: Typical low/high temperature for this day of the year\n\nRecordLow/RecordHigh: Record low/high temperature for this day of the year\n\nLowYr/HighYr: Year in which the record low/high was observed\n\nPrecip: Amount of precipitation (inches) this day\n\nRecordPrecip: Record amount of precipitation for this day of the year\n\nPrecipYr: Year in which the record precipitation was observed\n\ndate: The actual date in 2011 for this day in YYYY-MM-DD format\n\ndateInYear: What day of the year is it? (1-365)\n\nRecord: Logical (TRUE/FALSE) indicating whether this day had a high temperature record\n\nRecordText: Text that displays the record high for this day (\"Record high: ##\")\n\nRecordP: Logical (TRUE/FALSE) indicating whether this day had a precipitation record\n\nCulmPrec: Cumulative precipitation for the month up to this day",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#exercise-1",
    "href": "src/ica/Advanced_data_viz.html#exercise-1",
    "title": "3 Advanced Data Viz",
    "section": "Exercise 1",
    "text": "Exercise 1\nExamine the NYTimes 2015 Temperature Visualization (html) then answer the following questions.\nData Storytelling\n\nRelate the intro paragraph: “Scientists declared that 2015 was Earth’s hottest year on record…” to the design of the visualization. In particular, based on the intro paragraph,\n\nWhat key message/claim does NYTimes want readers to be able to explore? NYT wants readers to explore their own cities and see how 2015 compares to the historical average temperature over the course of a year regardless of location.\nHow did this goal inform what information is displayed in the visualization? It means that there is a part that shows the historical average and then one that shows the daily average from 2025 overlayed on one another. Then it also provides the option to switch through cities to compare how they have changed easier.\n\n\n\nAesthetic Mapping\n\nWhat specific variables (from the data codebook) underlie the visualization?\nHow do these variables map to aesthetics of the visual elements, eg, position, size, shape, and color of glyphs?\n\nFor x most likely the dateInYear or date variable, for y it is the Record Low/High overlayed with NormalHigh/NormalLow. Depending on the city there is RecordPrecip. Date in year makes up the x axis and is spkit into months very nicely, which each day making a small rectangular box. The record High and low are a redish pink cover overlayed on the grey to allow for comparison. The high and low make up either end of the box or each day, so longer boxes have more of a range of temperatures. Grey tends to take a more even slope/change as it are historical averages. They move from city to city up or down normally situating around a certain average temperature.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#exercise-2",
    "href": "src/ica/Advanced_data_viz.html#exercise-2",
    "title": "3 Advanced Data Viz",
    "section": "Exercise 2",
    "text": "Exercise 2\nNavigate the Geoms section of the ggplot2 reference page to find a geom that corresponds to the visual elements in the temperature plot. Using both the small thumbnail visuals on the right and the names of the geom’s, brainstorm some possibilities for geom’s you might use to recreate the temperature visualization.\n\n\n\n\n\n\nNavigating Documentation / Reference Pages\n\n\n\nYou need to navigate the geoms further by opening up their reference pages to understand if a particular geom is suitable for our task. Let’s look at the geom_point documentation page to learn how to read a documentation page..\nThe Usage section shows all of the possible inputs (arguments) to the geom. These are all of the ways that a geom can be customized. Just looking at the argument names can help give a hint as to what arguments might fit our needs.\nThe Arguments section, on the other hand, explains in detail what each argument does and the possible values the argument can take. The mapping, data, and ... arguments will be the most commonly used by far.\n\n\nmapping is the argument that is being used when we specify which variables should link or map to the plot aesthetics (the code inside aes()).\n\ndata is the argument where we specify the dataset containing the variables that the geom is using.\n\n... is used for fixed aesthetics (ones that don’t correspond to a variable), eg, to set the color of all points, we use color = \"red\" and to set the size of all points, we use size = 3.\n\nThe Aesthetics section of a geom documentation page gives information on how the visual elements of the geom correspond to data. For example, the geom_point documentation page shows that x and y aesthetics are available. It also shows some new aesthetics like stroke.\n\n\n\n\n\n\n\n\ndata Argument\n\n\n\nPreviously you have used one dataset per plot by specifying that as the first argument of ggplot(). However, multiple data sets can be passed into ggplot as shown in the example below.\n\nCodedata(diamonds)\n\ndiamonds_avg_price &lt;- diamonds |&gt;\n  group_by(carat) |&gt;\n  summarize(avg_price = mean(price)) |&gt;\n  arrange(carat)\ndiamonds_avg_price &lt;- diamonds_avg_price[seq(1, nrow(diamonds_avg_price), 3), ]\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_point() +\n  geom_point(\n    data = diamonds_avg_price,\n    aes(x = carat, y = avg_price),\n    color = \"deepskyblue\",\n    size = 3\n  )\n\n\n\n\n\n\n\n\n\nLook at the geom_linerange documentation page and start off your temperature visualization with the record lows and highs. Your plot should look like the one below. The hex code of the used light tan color is #ECEBE3.\n\n\nSFO Weather Records in 2011\n\n\nCodeggplot(weather) +\n  geom_linerange(aes(x = dateInYear, ymax = RecordHigh, ymin = RecordLow), color = \"#ECEBE3\" ) + \n    theme_classic()\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeyboard Shortcuts\n\n\n\nAs you work on this plot, try to use some new keyboard shortcuts. Focus on the following:\n\nInsert code chunk: Ctrl+Alt+I (Windows). Option+Command+I (Mac).\nRun current code chunk: Ctrl+Shift+Enter (Windows). Command+Shift+Return (Mac).\nRun current line/currently selected lines: Ctrl+Enter (Windows). Command+Return (Mac).",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#exercise-3",
    "href": "src/ica/Advanced_data_viz.html#exercise-3",
    "title": "3 Advanced Data Viz",
    "section": "Exercise 3",
    "text": "Exercise 3\nIn your visualization, also display the usual temperatures (NormalLow and NormalHigh) and actual 2011 temperatures (Low and High). Your plot should look like the one below. The hex code of the color used for the usual temperatures is \"#C8B8BA\" and for the color used for actual temperatures is \"#A90248\".\n\n\nSFO observed, Average, and Record Daily Temperatures in 2011\n\n\nCodeggplot(weather) +\n  geom_linerange(aes(x = dateInYear, ymax = RecordHigh, ymin = RecordLow), color = \"#ECEBE3\" ) + \n  geom_linerange(aes(x = dateInYear, ymax = NormalHigh, ymin = NormalLow), color = \"#C8B8BA\") + \n  geom_linerange(aes(x = dateInYear, ymax = High, ymin= Low), color = \"#A90248\") + \n  theme_classic() \n\n\n\n\n\n\n\n\n\n\n\n\n\nFiner Control\n\n\n\nIf you’d like finer control of the width of these lines/rectangles, check out the geom_rect documentation page.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#exercise-4",
    "href": "src/ica/Advanced_data_viz.html#exercise-4",
    "title": "3 Advanced Data Viz",
    "section": "Exercise 4",
    "text": "Exercise 4\nRecreate the visual demarcations of the months by adding vertical lines separating the months. Brainstorm how we might draw those vertical lines. What geom might we use? What subset of the data might we use in that geom layer to draw lines only at the month divisions?\n\nCode#Small data set with end of the month for each month, \nMonth_data &lt;- weather |&gt; \n  group_by(Month) |&gt; \n  filter(Day == max(Day)) |&gt; \n  ungroup()\n\nggplot() +\n  geom_linerange(data = weather, aes(x = dateInYear, ymax = RecordHigh, ymin = RecordLow), color = \"#ECEBE3\" ) + \n  geom_linerange(data = weather, aes(x = dateInYear, ymax = NormalHigh, ymin = NormalLow), color = \"#C8B8BA\") + \n  geom_linerange(data = weather, aes(x = dateInYear, ymax = High, ymin= Low), color = \"#A90248\") + \n  #geom_rect(data = weather, aes(x = dateInYear, ymax = High, ymin= Low), fill = \"#A90248\",alpha = 0.3, inherit.aes = FALSE) + \n  theme_classic() + \n  geom_vline(data = Month_data, aes(xintercept = dateInYear), linetype = \"dotted\")",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#exercise-5",
    "href": "src/ica/Advanced_data_viz.html#exercise-5",
    "title": "3 Advanced Data Viz",
    "section": "Exercise 5",
    "text": "Exercise 5\nChange the x-axis labels so that the month names display in the center of each month’s slice of the plot.\n\n\n\n\n\n\nMonth Names\n\n\n\nR has built-in variables called month.abb and month.name that contain abbreviated and full month names.\n\n\n\nCode#Small data set with end of the month for each month, \nMonth_data &lt;- weather |&gt; \n  group_by(Month) |&gt; \n  filter(Day == max(Day)) |&gt; \n  ungroup() \n\nMid_month &lt;- weather |&gt; \n  group_by(Month) |&gt; \n  summarize(across(where(is.numeric), ~mean(.x, na.rm = TRUE)))\n\nmonth_numeric &lt;- as.numeric(format(month, format = \"%U\"))\nmonth_label &lt;- format(month, format = \"%b\")\n\nggplot(weather) +\n  geom_linerange(aes(x = dateInYear, ymax = RecordHigh, ymin = RecordLow), color = \"#ECEBE3\" ) + \n  geom_linerange(aes(x = dateInYear, ymax = NormalHigh, ymin = NormalLow), color = \"#C8B8BA\") + \n  geom_linerange(aes(x = dateInYear, ymax = High, ymin= Low), color = \"#A90248\") + \n  scale_x_continuous(breaks = Mid_month$dateInYear, labels = month.abb) + \n  #geom_rect(data = weather, aes(x = dateInYear, ymax = High, ymin= Low), fill = \"#A90248\",alpha = 0.3, inherit.aes = FALSE) + \n  theme_classic() + \n  geom_vline(data = Month_data, aes(xintercept = dateInYear), linetype = \"dotted\")\n\n\n\n\n\n\n\nTry to figuring out this new challenge using search engines and large language models:\n\nSearch Engines. Use Google to search for possible solutions using the jargon that is most likely to return the most relevant results. Record search queries and your thought process in selecting which search results to look at first.\nLLMs. Use ChatGPT or Gemini with prompts that will most efficiently get you the desired results. Record the chat prompts used and output given. Evaluate the output. Do you fully understand the code generated? How can you tell that the generated code is correct?",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#exercise-6",
    "href": "src/ica/Advanced_data_viz.html#exercise-6",
    "title": "3 Advanced Data Viz",
    "section": "Exercise 6",
    "text": "Exercise 6\nCreate a precipitation plot that looks like the following. Note that\n\nThe triangles point to precipitation records–refer to the data codebook above for the RecordP variable.\nThe numbers on the plot indicate the total precipitation for the month–search the hjust and vjust options to adjust the alignment of the numbers.\nThe blue and tan colors hex codes are \"#32a3d8\" and \"#ebeae2\", respectively.\n\n\n\nSFO Precipitation in 2011\n\n\nCodeMonth_average &lt;- weather |&gt; \n  group_by(Month) |&gt; \n  summarize(CulmPrec = max(CulmPrec), dateInYear = max(dateInYear))\n\nRecord &lt;- weather |&gt; \n  filter(RecordP == TRUE) \n  \n\nggplot(weather, aes(x = dateInYear, y = CulmPrec)) +\n  geom_area(fill = \"#ebeae2\", alpha = 0.5) +\n  geom_line(color = \"#32a3d8\", size = 0.5) +  \n  geom_text(data = Month_average, aes(label = round(CulmPrec, 2)), \n            vjust = -0.5, size = 3) +\n  geom_point(data = Record, aes(x = dateInYear, y = CulmPrec), \n             shape = 25, fill = \"black\", size = 2) + \n  theme_minimal()",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#done",
    "href": "src/ica/Advanced_data_viz.html#done",
    "title": "3 Advanced Data Viz",
    "section": "Done!",
    "text": "Done!\n\nCheck the ICA Instructions for how to (a) push your code to GitHub and (b) update your portfolio website",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/Advanced_data_viz.html#footnotes",
    "href": "src/ica/Advanced_data_viz.html#footnotes",
    "title": "3 Advanced Data Viz",
    "section": "",
    "text": "The exercise in this lesson are inspired by an assignment from the Concepts in Computing with Data course at UC Berkeley taught by Dr. Deborah Nolan.↩︎",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Advanced Data Viz</span>"
    ]
  },
  {
    "objectID": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html",
    "href": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html",
    "title": "4 Advanced Spatial Viz P1",
    "section": "",
    "text": "🧩 Learning Goals\nBy the end of this lesson, you should be able to:",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 Advanced Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#learning-goals",
    "href": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#learning-goals",
    "title": "4 Advanced Spatial Viz P1",
    "section": "",
    "text": "Understand the basics of a CRS (coordinate reference system)\nUnderstand and recognize different spatial file types and data types in R\nImplement some of the basic plotting with the sf package\nUnderstand foundational ideas in working with spatial data (aggregating spatial point data to a spatial region, joining spatial data sets)",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 Advanced Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#additional-resources",
    "href": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#additional-resources",
    "title": "4 Advanced Spatial Viz P1",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nSpatial Data Science with Applications in R book: web\n\nSpatial Data Science with R and terra Resources: web\n\nLeaflet in R Package: web\n\nCRAN task view on spatial analysis: web",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 Advanced Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#setup",
    "href": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#setup",
    "title": "4 Advanced Spatial Viz P1",
    "section": "Setup",
    "text": "Setup\nFor this activity, create the following directory structure in your portfolio repository under src/ica folder:\nportfolio\n└─ src\n   └─ ica\n      └─ 04_adv_maps\n         ├─ code\n         │  └─ 04-adv-maps-1-notes.qmd\n         ├─ data\n         │  └─ ...  ← saving data here during this activity\n         └─ figures\n            └─ ...  ← saving created maps here during this activity\nFirst load required packages.\n\nCode#Install these packages first\n\n# install.packages(c(\"sf\",\"elevatr\",\"terra\",\"stars\",\"tidycensus\"))\n# install.packages('devtools')\n# devtools::install_github(\"ropensci/USAboundaries\")\n# install.packages(\"USAboundariesData\", repos = \"https://ropensci.r-universe.dev\", type = \"source\")\n\n\nlibrary(tidyverse)\nlibrary(sf) # tools for working with spatial vector data (GIS functionality, mapping)\nlibrary(elevatr) # access to raster elevation maps\nlibrary(terra)\nlibrary(stars)\nlibrary(tidycensus) # spatial data for the US with census information\nlibrary(USAboundaries) # access to boundaries for US states, counties, zip codes, and congressional districts",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 Advanced Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#spatial-data-in-r",
    "href": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#spatial-data-in-r",
    "title": "4 Advanced Spatial Viz P1",
    "section": "Spatial Data in R",
    "text": "Spatial Data in R\nSee Spatial Data Appendix for basics of CRS and spatial data types.\nDownload Shapefiles\n\nNavigate to the following URLs to download the spatial data files we’ll be using in this activity. Put these files in the data folder of your 04_adv_maps folder.\n\n\nMN cities: https://gisdata.mn.gov/dataset/loc-pop-centers\n\nFile type: shapefile (.shp)\nFile name: shp_loc_pop_centers.zip (Unzip this after downloading.)\n\n\nMN water: https://gisdata.mn.gov/dataset/us-mn-state-metc-water-lakes-rivers\n\nFile type: shapefile (.shp)\nFile name: shp_water_lakes_rivers.zip (Unzip this after downloading.)\n\n\nRead in Files\n\nRead in the MN cities and MN water shapefiles by entering the correct relative paths in st_read(). Tab completion will be very helpful here: type part of a directory or file name and hit tab to autocomplete or bring up a dropdown of options.\n\n\n\nCode# The sf package comes with a North Carolina shapefile:\nnc &lt;- st_read(system.file(\"shape/nc.shp\", package = \"sf\"))\n\nReading layer `nc' from data source \n  `/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/sf/shape/nc.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\nGeodetic CRS:  NAD27\n\nCode# Read in shapefiles just downloaded\nmn_cities &lt;- st_read(\"../data/shp_loc_pop_centers/city_and_township_population_centers.shp\")\n\nReading layer `city_and_township_population_centers' from data source \n  `/Users/toriduckworth/Documents/course_work/stat212/class_activities/portfolio-duckwor37/src/ica/04_adv_maps/data/shp_loc_pop_centers/city_and_township_population_centers.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1081 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 190832.6 ymin: 4816672 xmax: 747463.4 ymax: 5468045\nProjected CRS: NAD83 / UTM zone 15N\n\nCodemn_water &lt;- st_read(\"../data/shp_water_lakes_rivers/LakesAndRivers.shp\")\n\nReading layer `LakesAndRivers' from data source \n  `/Users/toriduckworth/Documents/course_work/stat212/class_activities/portfolio-duckwor37/src/ica/04_adv_maps/data/shp_water_lakes_rivers/LakesAndRivers.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2313 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 419538.6 ymin: 4922700 xmax: 522665 ymax: 5029945\nProjected CRS: NAD83 / UTM zone 15N\n\n\nThe sf package reads in spatial data in data.frame-like format. Using the class() function we can check the class (type) of object that we just read in. Note the presence of the “sf” and “data.frame” classes:\n\nCodeclass(nc)\n\n[1] \"sf\"         \"data.frame\"\n\nCodeclass(mn_cities)\n\n[1] \"sf\"         \"data.frame\"\n\nCodeclass(mn_water)\n\n[1] \"sf\"         \"data.frame\"\n\n\nWhen we read in spatial objects, it is useful to check what CRS underlies the data. We can do that with st_crs() from the sf package:\n\nCodest_crs(nc)\n\nCoordinate Reference System:\n  User input: NAD27 \n  wkt:\nGEOGCRS[\"NAD27\",\n    DATUM[\"North American Datum 1927\",\n        ELLIPSOID[\"Clarke 1866\",6378206.4,294.978698213898,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4267]]\n\n\nWe can treat sf objects similarly to ordinary datasets when using ggplot2 to make spatial visualizations:\n\nCodeggplot(nc) +\n    geom_sf() +\n    theme_classic() +\n    labs(title = \"NAD27\")\n\n\n\n\n\n\n\nChange CRS\n\nLet’s explore how changing the CRS changes the map. The st_transform() function in sf re-expresses a spatial object using a user-supplied CRS. The crs argument takes a string descriptor of the CRS. We can find these descriptors via https://epsg.io. In the example below, I searched for “South Carolina”.\n\n\nCodenc_transformed &lt;- nc |&gt; st_transform(crs = \"EPSG:32133\")\nst_crs(nc_transformed)\n\nCoordinate Reference System:\n  User input: EPSG:32133 \n  wkt:\nPROJCRS[\"NAD83 / South Carolina\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"SPCS83 South Carolina zone (meter)\",\n        METHOD[\"Lambert Conic Conformal (2SP)\",\n            ID[\"EPSG\",9802]],\n        PARAMETER[\"Latitude of false origin\",31.8333333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8821]],\n        PARAMETER[\"Longitude of false origin\",-81,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8822]],\n        PARAMETER[\"Latitude of 1st standard parallel\",34.8333333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8823]],\n        PARAMETER[\"Latitude of 2nd standard parallel\",32.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8824]],\n        PARAMETER[\"Easting at false origin\",609600,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8826]],\n        PARAMETER[\"Northing at false origin\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8827]]],\n    CS[Cartesian,2],\n        AXIS[\"easting (X)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"northing (Y)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"United States (USA) - South Carolina - counties of Abbeville; Aiken; Allendale; Anderson; Bamberg; Barnwell; Beaufort; Berkeley; Calhoun; Charleston; Cherokee; Chester; Chesterfield; Clarendon; Colleton; Darlington; Dillon; Dorchester; Edgefield; Fairfield; Florence; Georgetown; Greenville; Greenwood; Hampton; Horry; Jasper; Kershaw; Lancaster; Laurens; Lee; Lexington; Marion; Marlboro; McCormick; Newberry; Oconee; Orangeburg; Pickens; Richland; Saluda; Spartanburg; Sumter; Union; Williamsburg; York.\"],\n        BBOX[32.05,-83.36,35.21,-78.52]],\n    ID[\"EPSG\",32133]]\n\nCodeggplot(nc_transformed) +\n    geom_sf() +\n    theme_classic()\n\n\n\n\n\n\n\nThe goal is to use https://epsg.io to find two CRSs that result in a North Carolina map that is noticeably different from the original in the NAD27 CRS.\nTake a look at the function below that re-maps a spatial object using a new CRS.\n\nRead through the function to get a sense for how this code works.\n\nspatial_obj and new_crs are called arguments (function inputs).\n\nAdd one more argument called title to this function. Use this input to set the plot title.\n\n\nUse your function to make two new maps using your chosen CRSs.\n\n\nCodetransform_and_plot &lt;- function(spatial_obj, new_crs, title) {\n    spatial_obj |&gt; \n        st_transform(crs = new_crs) |&gt; \n        ggplot() +\n            geom_sf() +\n            theme_classic() + \n    labs(title = title)\n}\n\n# Example usage of this function (using a South Carolina CRS)\ntransform_and_plot(nc, new_crs = \"EPSG:32133\", title = \"South Carolina CRS\")\n\n\n\n\n\n\n\n\nCode#First map with different CRS \ntransform_and_plot(nc, new_crs = \"EPSG:3414\", title = \"Singapore CRS\")\n\n\n\n\n\n\n\n\nCode#Second map with different CRS \ntransform_and_plot(nc, new_crs = \"EPSG:3576\", title = \"Northen Hemisphere CRS (North of 45)\")\n\n\n\n\n\n\n\nVerify your understanding: If you had point location data that was not in the NAD27 CRS, what would you expect about the accuracy of how they would be overlaid on the original North Carolina map?\nIf you you had a point location data that was not in the NAD27 CRS, the accuracy of how it would be overlaid would be low. Since it is a map that is designed to fit another region of the world it will warp this section.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 Advanced Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#mn-map-with-multiple-layers",
    "href": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#mn-map-with-multiple-layers",
    "title": "4 Advanced Spatial Viz P1",
    "section": "MN Map with Multiple Layers",
    "text": "MN Map with Multiple Layers\nGoal: create a map of MN with different layers of information (city point locations, county polygon boundaries, rivers as lines and polygons, and a raster elevation map).\nGet County Boundaries\n\nWe’ve already read in city location and water information from external shapefiles. We can access county boundaries with the us_counties() function in the USAboundaries package.\n\n\nCode# Load country boundaries data as sf object\nmn_counties &lt;- USAboundaries::us_counties(resolution = \"high\", states = \"Minnesota\")\n\n# Take care of duplicate column names (there are two identical \"state_name\" columns)\nnames_counties &lt;- names(mn_counties)\nnames(mn_counties)[names_counties == \"state_name\"] &lt;- c(\"state_name1\", \"state_name2\")\n\n\nUnifying CRSs Across Different Spatial Datasets\n\nWe first need to ensure that the CRS is the same for all spatial datasets.\n\n\nCheck the CRS for the mn_cities, mn_water, and mn_counties datasets.\nIf the datasets don’t all have the same CRS, use st_transform() to update the datasets to have the same CRS as mn_cities. You can use crs = st_crs(mn_cities) within st_transform().\n\n\nCode#checking CRS for datasets \nst_crs(mn_cities)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\nCodest_crs(mn_water)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\nCodest_crs(mn_counties)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\nCode#transforming mn_counties to match\nmn_counties &lt;- mn_counties |&gt; \n  st_transform(crs = st_crs(mn_cities))\n\n\nCounties + Cities\n\nCreate a map where city locations are overlaid on a map of county boundaries.\n\n\nYou will need to call geom_sf() twice.\nMake the map background white.\nInstall the ggthemes package, and add the following layer to use a clean map theme: + ggthemes::theme_map()\n\n\n\nCodeggplot() + \n  geom_sf(data = mn_counties, fill = \"white\") + \n  geom_sf(data = mn_cities) + \n  ggthemes::theme_map() \n\n\n\n\n\n\n\nCustomize Colors\n\nWe can use traditional ggplot2 aesthetics (e.g., fill, color) to display location specific attributes. Below we only plot large cities, and we color and size cities according to their population.\n\n\nCodeggplot() +\n    geom_sf(data = mn_counties, fill = \"white\") + \n    geom_sf(data = mn_cities |&gt; filter(Population &gt;= 10000), mapping = aes(color = Population, size = Population)) + # cities layer\n    scale_color_viridis_c() + # continuous (gradient) color scale\n    labs(title = \"Minnesota Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() +\n    theme(legend.position = \"bottom\") # move legend\n\n\n\n\n\n\n\nLook up the scale_color_viridis_c() documentation via the ggplot2 reference.\n\nRead the function description at the top. What is the advantage of using this function for making color palettes? This function turns the colors into a scale that is seeable for color blind individuals making your data more accessable to more people.\nLook through the examples section. What is the difference between the _d(), _c(), and _b() variants of this function?\n\nThe d stands for discrete scale, while the c stands for continuous scale (such as the one used above), and the b stands for a binned scale. You have to use a different function depending on what sort of data you are using.\nAdding Elevation Raster Data\nWhere are large cities located? Is there some relationship to local geography/terrain?\n\nTo investigate these questions, we can obtain elevation data to include on the map using the elevatr package. We encounter two new functions here—we can look up their documentation to make sense of the code by entering the following in the Console:\n\n\n?elevatr::get_elev_raster\n?terra::as.data.frame\n\n\nCodeelevation &lt;- elevatr::get_elev_raster(mn_counties, z = 5, clip = \"bbox\")\nraster::crs(elevation) &lt;- sf::st_crs(mn_counties)\n\n# Convert to data frame for plotting\nelev_df &lt;- elevation |&gt; terra::as.data.frame(xy = TRUE)\ncolnames(elev_df) &lt;- c(\"x\", \"y\", \"elevation\")\n\n\nBuild on our existing map by adding a raster layer for elevation as the background.\n\nLook up the documentation for geom_raster() to plot the elevation data from elev_df. This will be the first layer of the plot.\nLook at the documentation for scale_fill_gradient() to add the following elevation color scale: \"darkgreen\" represents the lowest elevations, and \"white\" represents the highest elevations.\nAdd in the layers from the map above to show the largest cities and the county outlines. To remove a background color, use fill = NA.\n\n\nCodeggplot() +\n    geom_raster(data = elev_df, aes(x = x, y = y, fill = elevation)) + \n    scale_fill_gradient(high = \"white\", low = \"darkgreen\") + \n    geom_sf(data = mn_counties, fill = \"NA\") + \n    geom_sf(data = mn_cities |&gt; filter(Population &gt;= 10000), mapping = aes(color = Population, size = Population)) + # cities layer\n    scale_color_viridis_c() + # continuous (gradient) color scale\n    labs(title = \"Minnesota Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() +\n    theme(legend.position = \"bottom\")  # move legend \n\n\n\n\n\n\n\nZoom in to Twin Cities and Add Water\n\nThe bulk of the interesting information in this map is in the Twin Cities area. Let’s zoom in to this area.\n\n\nWe can use the st_bbox() function to get the bounding box for a spatial object—we do this after filtering to the 7 counties in the Twin Cities.\nWe then use st_crop() to trim a spatial object to a given bounding box.\n\n\nCodeseven_countyarea &lt;- mn_counties |&gt;\n    filter(name %in% c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\")) |&gt; \n    st_bbox()\nseven_countyarea\n\n     xmin      ymin      xmax      ymax \n 419967.1 4924212.8  521254.8 5029157.4 \n\nCodeelevation &lt;- elevatr::get_elev_raster(mn_counties |&gt; st_crop(seven_countyarea), z = 9, clip = \"bbox\")\nraster::crs(elevation) &lt;- sf::st_crs(mn_counties)\n\n# Convert to data frame for plotting\nelev_df &lt;- elevation |&gt; terra::as.data.frame(xy = TRUE)\ncolnames(elev_df) &lt;- c(\"x\", \"y\", \"elevation\")\n\n\nIn the plot below, we add a layer for water information and a coord_sf() layer to restrict the x and y-axis limits to the Twin Cities bounding box. (Without this layer, the map would zoom back out to show all counties and bodies of water).\n\nCodeggplot() +\n    geom_raster(data = elev_df, aes(x = x, y = y, fill = elevation)) + \n    geom_sf(data = mn_counties, fill = NA, color = \"black\") + # county boundary layer\n    geom_sf(data = mn_water, fill = \"lightsteelblue1\", color = \"lightsteelblue1\") + # NEW: river/lake layer\n    geom_sf(data = mn_cities |&gt; filter(Population &gt;= 10000), mapping = aes(color = Population, size = Population)) + # cities layer\n    scale_color_viridis_c(option = \"magma\") + # continuous (gradient) color scale\n    scale_fill_gradient(low = \"darkgreen\", high = \"white\") + # continuous (gradient) fill scale\n    coord_sf(xlim = seven_countyarea[c(\"xmin\", \"xmax\")], ylim = seven_countyarea[c(\"ymin\", \"ymax\")]) + # NEW: crop map to Twin Cities bounding box\n    labs(title = \"Twin Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() +\n    theme(legend.position = \"none\") # remove legend\n\n\n\n\n\n\n\nLet’s add to the above code chunk to save the map above to an image file called tc_map_zoom.png in the figures folder. The code example below shows a general template for saving a plot to file. Choose a reasonable width and height. (There are also jpeg() and pdf() functions for writing images.)\n\nCodepng(\"../figures/tc_map_zoom.png\", width = 500, height = 500)\nggplot() +\n    geom_raster(data = elev_df, aes(x = x, y = y, fill = elevation)) + \n    geom_sf(data = mn_counties, fill = NA, color = \"black\") + # county boundary layer\n    geom_sf(data = mn_water, fill = \"lightsteelblue1\", color = \"lightsteelblue1\") + # NEW: river/lake layer\n    geom_sf(data = mn_cities |&gt; filter(Population &gt;= 10000), mapping = aes(color = Population, size = Population)) + # cities layer\n    scale_color_viridis_c(option = \"magma\") + # continuous (gradient) color scale\n    scale_fill_gradient(low = \"darkgreen\", high = \"white\") + # continuous (gradient) fill scale\n    coord_sf(xlim = seven_countyarea[c(\"xmin\", \"xmax\")], ylim = seven_countyarea[c(\"ymin\", \"ymax\")]) + # NEW: crop map to Twin Cities bounding box\n    labs(title = \"Twin Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() +\n    theme(legend.position = \"none\") \ndev.off()",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 Advanced Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#going-beyond---twin-cities-map-with-leaflet",
    "href": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#going-beyond---twin-cities-map-with-leaflet",
    "title": "4 Advanced Spatial Viz P1",
    "section": "Going Beyond - Twin Cities Map with leaflet\n",
    "text": "Going Beyond - Twin Cities Map with leaflet\n\nBelow we show how to make the MN counties map in the leaflet package.\n\nCodelibrary(leaflet)\n\nmn_counties_leaf &lt;- mn_counties |&gt; st_transform(4326) # Leaflet expects this CRS for vectors\nmn_cities_leaf &lt;- mn_cities |&gt; st_transform(4326)\n\ncities_per_county &lt;- st_join(mn_cities_leaf, mn_counties_leaf) |&gt;\n    st_drop_geometry() |&gt; # removes geometry - makes the following calculation more efficient\n    count(name) \n\nmn_counties_leaf |&gt; \n    filter(name %in% c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\")) |&gt;\n    left_join(cities_per_county) |&gt;\n    leaflet() |&gt; \n    addProviderTiles(\"CartoDB.Positron\") |&gt; \n    addPolygons(\n        color = \"#444444\", weight = 1, smoothFactor = 0.5, opacity = 1.0,\n        fillOpacity = 0.5, fillColor = ~colorQuantile(\"YlOrRd\", n)(n),\n        highlightOptions = highlightOptions(color = \"white\", weight = 2, bringToFront = TRUE)) |&gt;\n    addCircles(data = mn_cities_leaf |&gt; filter(County %in% paste(c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\"), \"County\")), color = \"#444444\")",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 Advanced Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#done",
    "href": "src/ica/04_adv_maps/code/Advanced_spatial_data_viz_P1.html#done",
    "title": "4 Advanced Spatial Viz P1",
    "section": "Done!",
    "text": "Done!\n\nCheck the ICA Instructions for how to (a) push your code to GitHub and (b) update your portfolio website",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 Advanced Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "src/appx/appx-sample1.html",
    "href": "src/appx/appx-sample1.html",
    "title": "Appendix A — Appendix Sample 1",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendix Sample 1</span>"
    ]
  },
  {
    "objectID": "src/appx/appx-sample2.html",
    "href": "src/appx/appx-sample2.html",
    "title": "Appendix B — Appendix Sample 2",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix Sample 2</span>"
    ]
  },
  {
    "objectID": "mm/mm.html",
    "href": "mm/mm.html",
    "title": "Appendix C — Mind Maps",
    "section": "",
    "text": "Creativity",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Mind Maps</span>"
    ]
  },
  {
    "objectID": "mm/mm.html#creativity",
    "href": "mm/mm.html#creativity",
    "title": "Appendix C — Mind Maps",
    "section": "",
    "text": "0808-mind_map_example.jpg\n\n\n\n\n\n0905-Review_mind_map.jpeg\n\n\n\n\n\n0908-Data_Visualization.jpeg\n\n\n\n\n\n0910-Advanced_spatial_data_viz.jpeg",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Mind Maps</span>"
    ]
  }
]